{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "20213207 Assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "61c977a5536548c39dc2db374125b538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fee9b4eec4f470e928540a2195f7b10",
              "IPY_MODEL_71d9c51d4eb44eab9f5e0a2a0bcad8ae"
            ],
            "layout": "IPY_MODEL_ba865cc9b80b4e299de2157c83199f53"
          }
        },
        "ba865cc9b80b4e299de2157c83199f53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fee9b4eec4f470e928540a2195f7b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea4a794414ce44f191fae4ce7fe0db04",
            "max": 1053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68d5b736ec9540e5b8398b79f3935bf9",
            "value": 1053
          }
        },
        "71d9c51d4eb44eab9f5e0a2a0bcad8ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0531e86d3a164da6a59d2dfaa5cebd29",
            "placeholder": "​",
            "style": "IPY_MODEL_c6ede58ea9a24efebcacd845f0cc47a7",
            "value": " 1053/1053 [34:36&lt;00:00,  1.97s/it]"
          }
        },
        "68d5b736ec9540e5b8398b79f3935bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "ea4a794414ce44f191fae4ce7fe0db04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6ede58ea9a24efebcacd845f0cc47a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0531e86d3a164da6a59d2dfaa5cebd29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feed0327678c488ba9f09b5bac0e0608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e4b47414ccd46e9a9b637762b378a55",
              "IPY_MODEL_5403ee72abac4b9db37bdb1fd04d4c8b"
            ],
            "layout": "IPY_MODEL_7a79070241e3415cad14408c45877ba8"
          }
        },
        "7a79070241e3415cad14408c45877ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e4b47414ccd46e9a9b637762b378a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa6fbd0edbdf4fd284a015d5ced115d5",
            "max": 1053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c2b8dc142ba4184bba35edf1e738cb3",
            "value": 1053
          }
        },
        "5403ee72abac4b9db37bdb1fd04d4c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9d5fed39c7542709306cffd0856b54a",
            "placeholder": "​",
            "style": "IPY_MODEL_7836061dcb5842bbb234db4d6f93efdf",
            "value": " 1053/1053 [25:12&lt;00:00,  1.44s/it]"
          }
        },
        "0c2b8dc142ba4184bba35edf1e738cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "aa6fbd0edbdf4fd284a015d5ced115d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7836061dcb5842bbb234db4d6f93efdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9d5fed39c7542709306cffd0856b54a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa0ae329f561406fb13f6c080c88d56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef2cd0255d18409fabdc0b79903b92f6",
              "IPY_MODEL_cbb0dbcf2ebb4e3fb537654f32d19d73"
            ],
            "layout": "IPY_MODEL_c743303e84da44c4876371d3b64e9a20"
          }
        },
        "c743303e84da44c4876371d3b64e9a20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef2cd0255d18409fabdc0b79903b92f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a6ebb431c0d4bdd9502873f5561205b",
            "max": 1053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c420ac36cfc84828823b4e2709364b20",
            "value": 1053
          }
        },
        "cbb0dbcf2ebb4e3fb537654f32d19d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b12971824d4b465495f48e74333a3e37",
            "placeholder": "​",
            "style": "IPY_MODEL_6b5238d073294a449fe00b2442a19582",
            "value": " 1053/1053 [15:44&lt;00:00,  1.11it/s]"
          }
        },
        "c420ac36cfc84828823b4e2709364b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "7a6ebb431c0d4bdd9502873f5561205b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b5238d073294a449fe00b2442a19582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b12971824d4b465495f48e74333a3e37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d39ff41a51174783a14076629ddab91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49abcc1337574c5fb6695189bb923694",
              "IPY_MODEL_26c957f967b0479e986e6257ccac5bb6"
            ],
            "layout": "IPY_MODEL_46150ab4979c4ecfa042ba1795fb0f29"
          }
        },
        "46150ab4979c4ecfa042ba1795fb0f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49abcc1337574c5fb6695189bb923694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_260c3d7bc9ae4f21b42771d2ace02cf8",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87510dbbfb9344ff86e5d7f284b4781f",
            "value": 440473133
          }
        },
        "26c957f967b0479e986e6257ccac5bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_661ea5c2bf0d4a0384bdce8562afd878",
            "placeholder": "​",
            "style": "IPY_MODEL_c69daa5bc79c479195742fe889f87634",
            "value": " 440M/440M [26:57&lt;00:00, 272kB/s]"
          }
        },
        "87510dbbfb9344ff86e5d7f284b4781f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "260c3d7bc9ae4f21b42771d2ace02cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c69daa5bc79c479195742fe889f87634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "661ea5c2bf0d4a0384bdce8562afd878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0885b9a576a949aabd69e245491176c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fd3d0c55a1045f8a409c2d3cf59b77d",
              "IPY_MODEL_ebf633302a524e599253fcdf4de8e54d"
            ],
            "layout": "IPY_MODEL_3eda3139519842619ea72506d53728dd"
          }
        },
        "3eda3139519842619ea72506d53728dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fd3d0c55a1045f8a409c2d3cf59b77d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fa066e258824101be2b6a23b42cc48c",
            "max": 1053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e190ff18f714d7bb8f9771890420634",
            "value": 1053
          }
        },
        "ebf633302a524e599253fcdf4de8e54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85e32071c4c54754840f704215a44c95",
            "placeholder": "​",
            "style": "IPY_MODEL_0d1327cb22234ff4ab975938e3d59897",
            "value": " 1053/1053 [26:46&lt;00:00,  1.53s/it]"
          }
        },
        "1e190ff18f714d7bb8f9771890420634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "6fa066e258824101be2b6a23b42cc48c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d1327cb22234ff4ab975938e3d59897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85e32071c4c54754840f704215a44c95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43b98295a1de42949a9fc814ffb5a93b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6daf143297914fa6b1b4c993518ba8d8",
              "IPY_MODEL_7e02d181433e4d8a9593bf57baaf0f08"
            ],
            "layout": "IPY_MODEL_74ac46db1a874d0184d1e055acae82aa"
          }
        },
        "74ac46db1a874d0184d1e055acae82aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6daf143297914fa6b1b4c993518ba8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f176ddde6a954fd39331d9426a7c4d92",
            "max": 1053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_282632ce3fab4b4881acd8481aa12e43",
            "value": 1053
          }
        },
        "7e02d181433e4d8a9593bf57baaf0f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a24495f1e8264ab681689b3e3d6be312",
            "placeholder": "​",
            "style": "IPY_MODEL_d93934d9ad6f4718917b6f3e673df853",
            "value": " 1053/1053 [18:04&lt;00:00,  1.03s/it]"
          }
        },
        "282632ce3fab4b4881acd8481aa12e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "f176ddde6a954fd39331d9426a7c4d92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d93934d9ad6f4718917b6f3e673df853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a24495f1e8264ab681689b3e3d6be312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d19280e727644b3083865a93e1902756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87984d33efe64010849cffc90fcbb680",
              "IPY_MODEL_4d5fcd2af0d64843b54903315bc25aa5"
            ],
            "layout": "IPY_MODEL_3429df766a3445a7857c09e6b19e6504"
          }
        },
        "3429df766a3445a7857c09e6b19e6504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87984d33efe64010849cffc90fcbb680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52683621bd6c4a9ebf8c33ee10abdd7c",
            "max": 1053,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ede41e98f25d43ec8e4b74536c7c1c1a",
            "value": 1053
          }
        },
        "4d5fcd2af0d64843b54903315bc25aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c48063b673974dcd86574f42479562d1",
            "placeholder": "​",
            "style": "IPY_MODEL_c17885cf719d40cf8a21f4d025a2d130",
            "value": " 1053/1053 [09:05&lt;00:00,  1.93it/s]"
          }
        },
        "ede41e98f25d43ec8e4b74536c7c1c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "52683621bd6c4a9ebf8c33ee10abdd7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c17885cf719d40cf8a21f4d025a2d130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c48063b673974dcd86574f42479562d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov6d5DdmJBK1"
      },
      "source": [
        "# KAIST AI605 Assignment 4: Sequence and Token Classification with BERT\n",
        "Instructor: Minjoon Seo (minjoon@kaist.ac.kr)\n",
        "\n",
        "TA in charge: Seokin Seo (tzs930@kaist.ac.kr)\n",
        "\n",
        "**Due date**: May 29 (Wed) 11:00pm, 2021\n",
        "\n",
        "Your name: Seungwoo, Ryu\n",
        "\n",
        "Your student ID: 20213207\n",
        "\n",
        "Your collaborators: -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Dv5UaXWJjDG"
      },
      "source": [
        "## Assignment Objectives\n",
        "- Use BERT for sequence classification (Assignment 1)\n",
        "- Use BERT for token classification (Assignment 2)\n",
        "\n",
        "## Your Submission\n",
        "Your submission will be a link to a Colab notebook that has all written answers and is fully executable. You will submit your assignment via KLMS. Use in-line LaTeX (see below) for mathematical expressions. Collaboration among students is allowed but it is not a group assignment so make sure your answer and code are your own. Also make sure to mention your collaborators in your assignment with their names and their student ids.\n",
        "\n",
        "## Grading\n",
        "The entire assignment is out of 100 points. There are two bonus questions with 40 points altogether. Your final score can be higher than 100 points.\n",
        "\n",
        "\n",
        "## Environment\n",
        "You will only use Python 3.7 and PyTorch 1.8, which is already available on Colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoGPRds3I8fS",
        "outputId": "31252e43-b5d9-4096-d863-8b69e48d7711"
      },
      "source": [
        "from platform import python_version\n",
        "import torch\n",
        "\n",
        "print(\"python\", python_version())\n",
        "print(\"torch\", torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python 3.7.4\n",
            "torch 1.8.0+cu111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jKyyJ0DK2Ze"
      },
      "source": [
        "## 1. Hugging Face Transformers\n",
        "In this assignment, you will  use `transformers` library by Hugging Face. The library provides you an easy way to utilize diverse pretrained language models. You will be specifically asked to re-do sequence classification (sentiment analysis) and token classification (question answering) that you already did in your Assignment 1 and 2. \n",
        "\n",
        "First, install both `transformers` and `datasets` packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfIjOfsfPnEc",
        "outputId": "72e64087-7c4a-43a3-ad0b-12ab559f3707"
      },
      "source": [
        "!pip install transformers datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in ./anaconda3/lib/python3.7/site-packages (4.5.1)\n",
            "Requirement already satisfied: datasets in ./anaconda3/lib/python3.7/site-packages (1.6.0)\n",
            "Requirement already satisfied: packaging in ./anaconda3/lib/python3.7/site-packages (from transformers) (19.2)\n",
            "Requirement already satisfied: filelock in ./anaconda3/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in ./anaconda3/lib/python3.7/site-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./anaconda3/lib/python3.7/site-packages (from transformers) (2021.4.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in ./anaconda3/lib/python3.7/site-packages (from transformers) (0.23)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./anaconda3/lib/python3.7/site-packages (from transformers) (4.36.1)\n",
            "Requirement already satisfied: requests in ./anaconda3/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
            "Requirement already satisfied: numpy>=1.17 in ./anaconda3/lib/python3.7/site-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in ./anaconda3/lib/python3.7/site-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: multiprocess in ./anaconda3/lib/python3.7/site-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: dill in ./anaconda3/lib/python3.7/site-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: xxhash in ./anaconda3/lib/python3.7/site-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pandas in ./anaconda3/lib/python3.7/site-packages (from datasets) (0.25.1)\n",
            "Requirement already satisfied: pyarrow>=1.0.0 in ./anaconda3/lib/python3.7/site-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: fsspec in ./anaconda3/lib/python3.7/site-packages (from datasets) (0.5.2)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in ./anaconda3/lib/python3.7/site-packages (from datasets) (0.0.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in ./anaconda3/lib/python3.7/site-packages (from packaging->transformers) (2.4.2)\n",
            "Requirement already satisfied: six in ./anaconda3/lib/python3.7/site-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in ./anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (0.6.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./anaconda3/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./anaconda3/lib/python3.7/site-packages (from requests->transformers) (1.24.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.7/site-packages (from requests->transformers) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in ./anaconda3/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: joblib in ./anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (0.13.2)\n",
            "Requirement already satisfied: click in ./anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in ./anaconda3/lib/python3.7/site-packages (from pandas->datasets) (2.8.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in ./anaconda3/lib/python3.7/site-packages (from pandas->datasets) (2019.3)\n",
            "Requirement already satisfied: more-itertools in ./anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->transformers) (7.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSyUb0LTK-Pb"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "from time import time\n",
        "from typing import List\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import load_metric\n",
        "from dataclasses import dataclass\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from transformers import (AutoTokenizer, \n",
        "                          AutoModel,\n",
        "                          AutoModelForSequenceClassification, \n",
        "                          AutoModelForTokenClassification,\n",
        "                          AutoModelForQuestionAnswering,\n",
        "                          AutoConfig,\n",
        "                          BertConfig,\n",
        "                          BertModel,\n",
        "                          PreTrainedModel,\n",
        "                          PreTrainedTokenizer, \n",
        "                          BatchEncoding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVcoprpVPquz"
      },
      "source": [
        "In Lecture 17, we walked through how we can use pretrained and finetuned BERT for sequence classification (https://huggingface.co/transformers/task_summary.html#sequence-classification) and token classification (https://huggingface.co/transformers/task_summary.html#extractive-question-answering).\n",
        "Recall that `bert-base-cased-finetuned-mrpc` means that you load a pretrained `bert-base-cased` model and you finetune it on `mrpc` dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_e9oRoCePmo"
      },
      "source": [
        "**Problem 1.1** *(10 points)* Put your favorite emoji here 😇\n",
        "https://getemoji.com/\n",
        "\n",
        "Your favorite emoji: 💯"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkrdGANFQ5ho"
      },
      "source": [
        "## 2. Sequence Classification with BERT\n",
        "**Problem 2.1** *(20 points)* Tutorial at https://huggingface.co/transformers/training.html#fine-tuning-in-native-pytorch shows you how you can finetune a sequence classification model from `bert-base-cased` for IMDB dataset. Repeat the same process with SST-2 dataset and report the accuracy here (i.e. it's fine to copy & paste code from the documentation).\n",
        "\n",
        "Note that you can load SST-2 dataset via\n",
        "\n",
        "**Answer to Problem 2.1**\n",
        "\n",
        "\n",
        "Accuracy: About 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLzjsPt0OENM",
        "outputId": "9b820b67-d54b-435e-c35e-9c4565ddf69b"
      },
      "source": [
        "from datasets import load_dataset, load_metric\n",
        "dataset = load_dataset('glue', 'sst2')\n",
        "metric = load_metric('accuracy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/home/swryu/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B50qwJ1XR1Wb"
      },
      "source": [
        "The dataset does not have labels for `test` data so please use `validation` data as your test data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "61c977a5536548c39dc2db374125b538",
            "ba865cc9b80b4e299de2157c83199f53",
            "1fee9b4eec4f470e928540a2195f7b10",
            "71d9c51d4eb44eab9f5e0a2a0bcad8ae",
            "68d5b736ec9540e5b8398b79f3935bf9",
            "ea4a794414ce44f191fae4ce7fe0db04",
            "c6ede58ea9a24efebcacd845f0cc47a7",
            "0531e86d3a164da6a59d2dfaa5cebd29",
            "feed0327678c488ba9f09b5bac0e0608",
            "7a79070241e3415cad14408c45877ba8",
            "9e4b47414ccd46e9a9b637762b378a55",
            "5403ee72abac4b9db37bdb1fd04d4c8b",
            "0c2b8dc142ba4184bba35edf1e738cb3",
            "aa6fbd0edbdf4fd284a015d5ced115d5",
            "7836061dcb5842bbb234db4d6f93efdf",
            "a9d5fed39c7542709306cffd0856b54a",
            "fa0ae329f561406fb13f6c080c88d56c",
            "c743303e84da44c4876371d3b64e9a20",
            "ef2cd0255d18409fabdc0b79903b92f6",
            "cbb0dbcf2ebb4e3fb537654f32d19d73",
            "c420ac36cfc84828823b4e2709364b20",
            "7a6ebb431c0d4bdd9502873f5561205b",
            "6b5238d073294a449fe00b2442a19582",
            "b12971824d4b465495f48e74333a3e37"
          ]
        },
        "id": "eAJyr2izJh1O",
        "outputId": "7d1da2d9-9ea7-46bc-a629-c4e65871de73"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-cased', num_labels=2).to(device)\n",
        "\n",
        "train_dataset = dataset['train']\n",
        "valid_dataset = dataset['validation']\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=64)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "CELoss = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loss_list = []\n",
        "\n",
        "model.train()\n",
        "for epoch in range(3):\n",
        "  train_loss = 0\n",
        "  for batch_idx, data in enumerate(tqdm(train_loader)):\n",
        "    feature = data['sentence']\n",
        "    label = data['label'].to(device)\n",
        "    tknz_batch = tokenizer(feature,\n",
        "                          padding='longest',\n",
        "                          truncation=True)\n",
        "    tknz_batch = {k: torch.tensor(v).to(device) for k, v in tknz_batch.items()}\n",
        "    outputs = model(**tknz_batch)\n",
        "    loss = CELoss(outputs.logits, label)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss\n",
        "\n",
        "    if batch_idx % 50 == 0:\n",
        "      print('Epoch: %03d/%03d | Batch %04d/%04d | Loss: %.4f' \n",
        "      %(epoch+1, 3, batch_idx, len(train_loader), loss))\n",
        "          \n",
        "  train_loss_list.append(train_loss/len(train_loader))\n",
        "\n",
        "print(f\"Loss change: {train_loss_list[0]} -> {train_loss_list[1]} -> {train_loss_list[2]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61c977a5536548c39dc2db374125b538",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1053.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001/003 | Batch 0000/1053 | Loss: 1.1252\n",
            "Epoch: 001/003 | Batch 0050/1053 | Loss: 0.3296\n",
            "Epoch: 001/003 | Batch 0100/1053 | Loss: 0.2505\n",
            "Epoch: 001/003 | Batch 0150/1053 | Loss: 0.2783\n",
            "Epoch: 001/003 | Batch 0200/1053 | Loss: 0.2572\n",
            "Epoch: 001/003 | Batch 0250/1053 | Loss: 0.2584\n",
            "Epoch: 001/003 | Batch 0300/1053 | Loss: 0.1243\n",
            "Epoch: 001/003 | Batch 0350/1053 | Loss: 0.2006\n",
            "Epoch: 001/003 | Batch 0400/1053 | Loss: 0.3084\n",
            "Epoch: 001/003 | Batch 0450/1053 | Loss: 0.2515\n",
            "Epoch: 001/003 | Batch 0500/1053 | Loss: 0.2149\n",
            "Epoch: 001/003 | Batch 0550/1053 | Loss: 0.0898\n",
            "Epoch: 001/003 | Batch 0600/1053 | Loss: 0.1927\n",
            "Epoch: 001/003 | Batch 0650/1053 | Loss: 0.2424\n",
            "Epoch: 001/003 | Batch 0700/1053 | Loss: 0.1238\n",
            "Epoch: 001/003 | Batch 0750/1053 | Loss: 0.2105\n",
            "Epoch: 001/003 | Batch 0800/1053 | Loss: 0.1653\n",
            "Epoch: 001/003 | Batch 0850/1053 | Loss: 0.2956\n",
            "Epoch: 001/003 | Batch 0900/1053 | Loss: 0.3308\n",
            "Epoch: 001/003 | Batch 0950/1053 | Loss: 0.1293\n",
            "Epoch: 001/003 | Batch 1000/1053 | Loss: 0.1314\n",
            "Epoch: 001/003 | Batch 1050/1053 | Loss: 0.2492\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "feed0327678c488ba9f09b5bac0e0608",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1053.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 002/003 | Batch 0000/1053 | Loss: 0.1716\n",
            "Epoch: 002/003 | Batch 0050/1053 | Loss: 0.1266\n",
            "Epoch: 002/003 | Batch 0100/1053 | Loss: 0.0574\n",
            "Epoch: 002/003 | Batch 0150/1053 | Loss: 0.0960\n",
            "Epoch: 002/003 | Batch 0200/1053 | Loss: 0.1520\n",
            "Epoch: 002/003 | Batch 0250/1053 | Loss: 0.0893\n",
            "Epoch: 002/003 | Batch 0300/1053 | Loss: 0.0871\n",
            "Epoch: 002/003 | Batch 0350/1053 | Loss: 0.0654\n",
            "Epoch: 002/003 | Batch 0400/1053 | Loss: 0.0704\n",
            "Epoch: 002/003 | Batch 0450/1053 | Loss: 0.1128\n",
            "Epoch: 002/003 | Batch 0500/1053 | Loss: 0.0781\n",
            "Epoch: 002/003 | Batch 0550/1053 | Loss: 0.1201\n",
            "Epoch: 002/003 | Batch 0600/1053 | Loss: 0.0925\n",
            "Epoch: 002/003 | Batch 0650/1053 | Loss: 0.1660\n",
            "Epoch: 002/003 | Batch 0700/1053 | Loss: 0.1180\n",
            "Epoch: 002/003 | Batch 0750/1053 | Loss: 0.1991\n",
            "Epoch: 002/003 | Batch 0800/1053 | Loss: 0.1135\n",
            "Epoch: 002/003 | Batch 0850/1053 | Loss: 0.1347\n",
            "Epoch: 002/003 | Batch 0900/1053 | Loss: 0.1472\n",
            "Epoch: 002/003 | Batch 0950/1053 | Loss: 0.1240\n",
            "Epoch: 002/003 | Batch 1000/1053 | Loss: 0.1748\n",
            "Epoch: 002/003 | Batch 1050/1053 | Loss: 0.1002\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa0ae329f561406fb13f6c080c88d56c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1053.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 003/003 | Batch 0000/1053 | Loss: 0.1127\n",
            "Epoch: 003/003 | Batch 0050/1053 | Loss: 0.1796\n",
            "Epoch: 003/003 | Batch 0100/1053 | Loss: 0.0777\n",
            "Epoch: 003/003 | Batch 0150/1053 | Loss: 0.0701\n",
            "Epoch: 003/003 | Batch 0200/1053 | Loss: 0.0067\n",
            "Epoch: 003/003 | Batch 0250/1053 | Loss: 0.0254\n",
            "Epoch: 003/003 | Batch 0300/1053 | Loss: 0.0749\n",
            "Epoch: 003/003 | Batch 0350/1053 | Loss: 0.1357\n",
            "Epoch: 003/003 | Batch 0400/1053 | Loss: 0.1171\n",
            "Epoch: 003/003 | Batch 0450/1053 | Loss: 0.0492\n",
            "Epoch: 003/003 | Batch 0500/1053 | Loss: 0.0633\n",
            "Epoch: 003/003 | Batch 0550/1053 | Loss: 0.0316\n",
            "Epoch: 003/003 | Batch 0600/1053 | Loss: 0.0571\n",
            "Epoch: 003/003 | Batch 0650/1053 | Loss: 0.1549\n",
            "Epoch: 003/003 | Batch 0700/1053 | Loss: 0.0725\n",
            "Epoch: 003/003 | Batch 0750/1053 | Loss: 0.0603\n",
            "Epoch: 003/003 | Batch 0800/1053 | Loss: 0.0708\n",
            "Epoch: 003/003 | Batch 0850/1053 | Loss: 0.0311\n",
            "Epoch: 003/003 | Batch 0900/1053 | Loss: 0.0198\n",
            "Epoch: 003/003 | Batch 0950/1053 | Loss: 0.0447\n",
            "Epoch: 003/003 | Batch 1000/1053 | Loss: 0.0788\n",
            "Epoch: 003/003 | Batch 1050/1053 | Loss: 0.0634\n",
            "\n",
            "Loss change: 0.2238498479127884 -> 0.11615826189517975 -> 0.07959772646427155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82W1OkAgGaXT",
        "outputId": "870589f9-84d7-450d-eecb-24eb459202c4"
      },
      "source": [
        "model.eval()\n",
        "for data in valid_loader:\n",
        "  feature = data['sentence']\n",
        "  label = data['label'].to(device)\n",
        "  tknz_batch = tokenizer(feature, \n",
        "                         padding='longest',\n",
        "                         truncation=True)\n",
        "  tknz_batch = {k: torch.tensor(v).to(device) for k, v in tknz_batch.items()}\n",
        "  with torch.no_grad(): \n",
        "    outputs = model(**tknz_batch)\n",
        "    \n",
        "  logits = outputs.logits\n",
        "  predictions = torch.argmax(logits, dim=-1)\n",
        "  metric.add_batch(predictions=predictions, references=label)\n",
        "\n",
        "metric.compute()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9013761467889908}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI1MSJYASQXx"
      },
      "source": [
        "\n",
        "**Problem 2.2** *(10 points)* How does your accuracy with BERT compares to your accuracy with LSTM in Assignment 1? How about training speed?\n",
        "\n",
        "\n",
        "**Answer to Problem 2.2** On the assignment1, the accuracy with LSTM was about 80%. And even, when I used dropout to enhance the performance, the best performance I got was about 83%. However, by using BERT, I could enhance the accuracy about 7% easily. I could feel the power of pretrained model which is pre-trained on large vocab. However, at the expense of improvement of accuracy, it took much more time for training than LSTM. It is becacuse BERT uses transformer encoders.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK_TSVZ7SRQv"
      },
      "source": [
        "**Problem 2.3** *(10 points)* Try your own sentences and find three failure cases. Explain why you think the model got them wrong.\n",
        "\n",
        "**Answer to Problem 2.3**  Of course I know three examples below are really extremely non-sense examples. But, for the extreme case, if someone writes the vocab which has really important role at predicting the sentiment in a strange way, for example, `not` as `nOT` or `sad` as `sAD`, the model cannot judge their implicit meaning. For three sentences I took, it is too easy for human to judge whether it's positive or negative. However, cased model got zero accuracy. This is the reason why, in some cases, we need uncased version model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g860r43XmAgh",
        "outputId": "7c8e6432-ef23-4627-d85b-14f0d1cba8df"
      },
      "source": [
        "sentence = ['I HATE THEM!',\n",
        "            'I dO nOT LOVE YOU!',\n",
        "            'I am really sAD hearing that another project assignment comes!']\n",
        "\n",
        "tknz_batch = tokenizer(sentence, padding='longest', truncation=True)\n",
        "tknz_batch = {k: torch.tensor(v) for k, v in tknz_batch.items()}\n",
        "\n",
        "model.cpu().eval()\n",
        "with torch.no_grad():\n",
        "  outputs = model(**tknz_batch)\n",
        "\n",
        "logits = outputs.logits\n",
        "predictions = torch.argmax(logits, dim=-1)\n",
        "metric.compute(predictions=predictions, references=torch.LongTensor([0,0,0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yANhl6GrMnx4"
      },
      "source": [
        "**Problem 2.4 (bonus)** *(20 points)*  Try `bert-base-uncased` and analyze if it makes any difference. What is the difference between `cased` and `uncased` in English? How about in Korean?\n",
        "\n",
        "**Answer to Problem 2.4** Accuracy is improved about 0.7%. It is not that much as I expected, but anyway it is improved. That might be because, now the model can consider the vocabs which were once not carefully considered on cased case. In Korean, there's no need to consider about cased, uncased. However, as far as I know, performing an NLP task on Korean is difficult based on different reasons. For example, Korean can deform in a various colloquial forms(구어체), and due to the existence of polite expression(경어체), it is difficult to consider them on the context in a consistent way. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d39ff41a51174783a14076629ddab91e",
            "46150ab4979c4ecfa042ba1795fb0f29",
            "49abcc1337574c5fb6695189bb923694",
            "26c957f967b0479e986e6257ccac5bb6",
            "87510dbbfb9344ff86e5d7f284b4781f",
            "260c3d7bc9ae4f21b42771d2ace02cf8",
            "c69daa5bc79c479195742fe889f87634",
            "661ea5c2bf0d4a0384bdce8562afd878",
            "0885b9a576a949aabd69e245491176c5",
            "3eda3139519842619ea72506d53728dd",
            "1fd3d0c55a1045f8a409c2d3cf59b77d",
            "ebf633302a524e599253fcdf4de8e54d",
            "1e190ff18f714d7bb8f9771890420634",
            "6fa066e258824101be2b6a23b42cc48c",
            "0d1327cb22234ff4ab975938e3d59897",
            "85e32071c4c54754840f704215a44c95",
            "43b98295a1de42949a9fc814ffb5a93b",
            "74ac46db1a874d0184d1e055acae82aa",
            "6daf143297914fa6b1b4c993518ba8d8",
            "7e02d181433e4d8a9593bf57baaf0f08",
            "282632ce3fab4b4881acd8481aa12e43",
            "f176ddde6a954fd39331d9426a7c4d92",
            "d93934d9ad6f4718917b6f3e673df853",
            "a24495f1e8264ab681689b3e3d6be312",
            "d19280e727644b3083865a93e1902756",
            "3429df766a3445a7857c09e6b19e6504",
            "87984d33efe64010849cffc90fcbb680",
            "4d5fcd2af0d64843b54903315bc25aa5",
            "ede41e98f25d43ec8e4b74536c7c1c1a",
            "52683621bd6c4a9ebf8c33ee10abdd7c",
            "c17885cf719d40cf8a21f4d025a2d130",
            "c48063b673974dcd86574f42479562d1"
          ]
        },
        "id": "ClfS2fTkn0dp",
        "outputId": "663f7947-147c-47e9-920b-84d0cfb0ff4f"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "train_loss_list = []\n",
        "\n",
        "model.train()\n",
        "for epoch in range(3):\n",
        "  train_loss = 0\n",
        "  for batch_idx, data in enumerate(tqdm(train_loader)):\n",
        "    feature = data['sentence']\n",
        "    label = data['label'].to(device)\n",
        "    tknz_batch = tokenizer(feature,\n",
        "                          padding='longest',\n",
        "                          truncation=True)\n",
        "    tknz_batch = {k: torch.tensor(v).to(device) for k, v in tknz_batch.items()}\n",
        "    outputs = model(**tknz_batch)\n",
        "    loss = CELoss(outputs.logits, label)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss\n",
        "\n",
        "    if batch_idx % 50 == 0:\n",
        "      print('Epoch: %03d/%03d | Batch %04d/%04d | Loss: %.4f' \n",
        "      %(epoch+1, 3, batch_idx, len(train_loader), loss))\n",
        "          \n",
        "  train_loss_list.append(train_loss/len(train_loader))\n",
        "\n",
        "print(f\"Loss change: {train_loss_list[0]} -> {train_loss_list[1]} -> {train_loss_list[2]}\")\n",
        "\n",
        "model.eval()\n",
        "for data in valid_loader:\n",
        "  feature = data['sentence']\n",
        "  label = data['label'].to(device)\n",
        "  tknz_batch = tokenizer(feature, \n",
        "                         padding='longest',\n",
        "                         truncation=True)\n",
        "  tknz_batch = {k: torch.tensor(v).to(device) for k, v in tknz_batch.items()}\n",
        "  with torch.no_grad(): \n",
        "    outputs = model(**tknz_batch)\n",
        "    \n",
        "  logits = outputs.logits\n",
        "  predictions = torch.argmax(logits, dim=-1)\n",
        "  metric.add_batch(predictions=predictions, references=label)\n",
        "\n",
        "metric.compute()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d39ff41a51174783a14076629ddab91e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0885b9a576a949aabd69e245491176c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1053.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001/003 | Batch 0000/1053 | Loss: 0.6911\n",
            "Epoch: 001/003 | Batch 0050/1053 | Loss: 0.2858\n",
            "Epoch: 001/003 | Batch 0100/1053 | Loss: 0.2995\n",
            "Epoch: 001/003 | Batch 0150/1053 | Loss: 0.1466\n",
            "Epoch: 001/003 | Batch 0200/1053 | Loss: 0.1593\n",
            "Epoch: 001/003 | Batch 0250/1053 | Loss: 0.1977\n",
            "Epoch: 001/003 | Batch 0300/1053 | Loss: 0.1251\n",
            "Epoch: 001/003 | Batch 0350/1053 | Loss: 0.1702\n",
            "Epoch: 001/003 | Batch 0400/1053 | Loss: 0.2936\n",
            "Epoch: 001/003 | Batch 0450/1053 | Loss: 0.2211\n",
            "Epoch: 001/003 | Batch 0500/1053 | Loss: 0.0708\n",
            "Epoch: 001/003 | Batch 0550/1053 | Loss: 0.1532\n",
            "Epoch: 001/003 | Batch 0600/1053 | Loss: 0.3943\n",
            "Epoch: 001/003 | Batch 0650/1053 | Loss: 0.2596\n",
            "Epoch: 001/003 | Batch 0700/1053 | Loss: 0.2320\n",
            "Epoch: 001/003 | Batch 0750/1053 | Loss: 0.1723\n",
            "Epoch: 001/003 | Batch 0800/1053 | Loss: 0.1279\n",
            "Epoch: 001/003 | Batch 0850/1053 | Loss: 0.0784\n",
            "Epoch: 001/003 | Batch 0900/1053 | Loss: 0.2068\n",
            "Epoch: 001/003 | Batch 0950/1053 | Loss: 0.1719\n",
            "Epoch: 001/003 | Batch 1000/1053 | Loss: 0.0672\n",
            "Epoch: 001/003 | Batch 1050/1053 | Loss: 0.1311\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43b98295a1de42949a9fc814ffb5a93b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1053.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 002/003 | Batch 0000/1053 | Loss: 0.0543\n",
            "Epoch: 002/003 | Batch 0050/1053 | Loss: 0.0322\n",
            "Epoch: 002/003 | Batch 0100/1053 | Loss: 0.0651\n",
            "Epoch: 002/003 | Batch 0150/1053 | Loss: 0.0353\n",
            "Epoch: 002/003 | Batch 0200/1053 | Loss: 0.0203\n",
            "Epoch: 002/003 | Batch 0250/1053 | Loss: 0.0891\n",
            "Epoch: 002/003 | Batch 0300/1053 | Loss: 0.1247\n",
            "Epoch: 002/003 | Batch 0350/1053 | Loss: 0.0723\n",
            "Epoch: 002/003 | Batch 0400/1053 | Loss: 0.2276\n",
            "Epoch: 002/003 | Batch 0450/1053 | Loss: 0.0602\n",
            "Epoch: 002/003 | Batch 0500/1053 | Loss: 0.0335\n",
            "Epoch: 002/003 | Batch 0550/1053 | Loss: 0.0879\n",
            "Epoch: 002/003 | Batch 0600/1053 | Loss: 0.0632\n",
            "Epoch: 002/003 | Batch 0650/1053 | Loss: 0.1487\n",
            "Epoch: 002/003 | Batch 0700/1053 | Loss: 0.0422\n",
            "Epoch: 002/003 | Batch 0750/1053 | Loss: 0.0198\n",
            "Epoch: 002/003 | Batch 0800/1053 | Loss: 0.0819\n",
            "Epoch: 002/003 | Batch 0850/1053 | Loss: 0.2010\n",
            "Epoch: 002/003 | Batch 0900/1053 | Loss: 0.0478\n",
            "Epoch: 002/003 | Batch 0950/1053 | Loss: 0.0468\n",
            "Epoch: 002/003 | Batch 1000/1053 | Loss: 0.2595\n",
            "Epoch: 002/003 | Batch 1050/1053 | Loss: 0.0540\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d19280e727644b3083865a93e1902756",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1053.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 003/003 | Batch 0000/1053 | Loss: 0.0600\n",
            "Epoch: 003/003 | Batch 0050/1053 | Loss: 0.0372\n",
            "Epoch: 003/003 | Batch 0100/1053 | Loss: 0.0378\n",
            "Epoch: 003/003 | Batch 0150/1053 | Loss: 0.0511\n",
            "Epoch: 003/003 | Batch 0200/1053 | Loss: 0.0228\n",
            "Epoch: 003/003 | Batch 0250/1053 | Loss: 0.0741\n",
            "Epoch: 003/003 | Batch 0300/1053 | Loss: 0.1339\n",
            "Epoch: 003/003 | Batch 0350/1053 | Loss: 0.0446\n",
            "Epoch: 003/003 | Batch 0400/1053 | Loss: 0.0121\n",
            "Epoch: 003/003 | Batch 0450/1053 | Loss: 0.1015\n",
            "Epoch: 003/003 | Batch 0500/1053 | Loss: 0.0179\n",
            "Epoch: 003/003 | Batch 0550/1053 | Loss: 0.0621\n",
            "Epoch: 003/003 | Batch 0600/1053 | Loss: 0.1289\n",
            "Epoch: 003/003 | Batch 0650/1053 | Loss: 0.0181\n",
            "Epoch: 003/003 | Batch 0700/1053 | Loss: 0.0629\n",
            "Epoch: 003/003 | Batch 0750/1053 | Loss: 0.0511\n",
            "Epoch: 003/003 | Batch 0800/1053 | Loss: 0.0083\n",
            "Epoch: 003/003 | Batch 0850/1053 | Loss: 0.0907\n",
            "Epoch: 003/003 | Batch 0900/1053 | Loss: 0.1407\n",
            "Epoch: 003/003 | Batch 0950/1053 | Loss: 0.1674\n",
            "Epoch: 003/003 | Batch 1000/1053 | Loss: 0.0246\n",
            "Epoch: 003/003 | Batch 1050/1053 | Loss: 0.1850\n",
            "\n",
            "Loss change: 0.20128753781318665 -> 0.10516040027141571 -> 0.07136944681406021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.908256880733945}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXzxRKbFSR1V"
      },
      "source": [
        "## 3. Token Classification with BERT\n",
        "**Problem 3.1** *(30 points)* Finetune your `bert-base-cased` model for `squad` question answering dataset, following a similar procedure to Problem 2.1. Report your accuracy here. For now, if the input is longer than 256, take the first 256 words as the input and truncate the rest. You are allowed to copy any code from the documentation.  *Hint*: If you are having difficulty in implementation, take a peek at  (but do not copy!) https://github.com/huggingface/transformers/tree/master/examples/pytorch/question-answering, though keep in mind that the answer extraction module there is quite complex. It is okay to keep it simple here and sacrifice the accuracy a little.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVlYTfH9j0ok"
      },
      "source": [
        "**Answer to Problem 3.1** The accuracy I got is about 7.2 in EM, and about 10.8 in F1 score. I made inputs in the format of `question + context` as I did in Problem 2.1. For the fair comparison, because there can be a lot of cases where the answers appear after the 256th token, I excluded those cases at the performance evaluation step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR9VSxROx4Oi",
        "outputId": "e4221de2-1a6d-4a1c-db9e-0cdba28cbfc0"
      },
      "source": [
        "dataset = load_dataset('squad')\n",
        "squad_metric = load_metric('squad')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset squad (/home/swryu/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bq5BGvniyto",
        "outputId": "0290e9e8-04ee-47e5-d9ba-b9f746c4358d"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "def start_end_index(squad_dataset, kind: str):\n",
        "  \"\"\"\n",
        "  kind: 'train' or 'validation'\n",
        "  In my case, I'm going to choose only the first index of 'text' in references, because there'are so much unnecessary overlays in validation set.\n",
        "  And also, I'm going to exclude few cases with tokenized 'text' length smaller than 3. \n",
        "  \"\"\"\n",
        "  qc_list = []\n",
        "  references = []\n",
        "  text_dict = OrderedDict()\n",
        "  start_end_index_dict = OrderedDict()\n",
        "\n",
        "  dataset = squad_dataset[kind]\n",
        "  total_data_cnt = len(dataset)\n",
        "  strange_case_cnt = 0\n",
        "  index_to_exclude = [] # To exclude datasets correspondig to these indices, later. \n",
        "\n",
        "  for i in range(total_data_cnt): # 87599 in training set, 10570 in validation set \n",
        "    data = dataset[i]\n",
        "    question = data['question']\n",
        "    context = data['context']\n",
        "    text = data['answers']['text']\n",
        "    reference_dict = dict()\n",
        "\n",
        "    if len(text) == 0: # If there's no answer?\n",
        "      continue\n",
        "\n",
        "    elif len(text) > 1: # Multi answers case => Too much overlap => Going to choose the only first answer \n",
        "      temp_dict = dict()\n",
        "      temp_answer_start = data['answers']['answer_start'][0]\n",
        "      temp_answer_text = data['answers']['text'][0]\n",
        "      temp_dict['answer_start'] = [temp_answer_start]\n",
        "      temp_dict['text'] = [temp_answer_text]\n",
        "      reference_dict['answers'] = temp_dict\n",
        "\n",
        "    else:\n",
        "      reference_dict['answers'] = data['answers']\n",
        "    reference_dict['id'] = data['id']\n",
        "    \n",
        "    concatenated = tokenizer(question, context, truncation=True, max_length=256) \n",
        "    text_interest = text[0]\n",
        "    text_tknz = tokenizer(text_interest)['input_ids']\n",
        "\n",
        "    start = None\n",
        "    end = None\n",
        "    flag = False\n",
        "\n",
        "    for index in range(len(concatenated['input_ids'])):\n",
        "        \n",
        "        if concatenated['input_ids'][index:index+(len(text_tknz)-2)] == text_tknz[1:-1]: # -2 & [1:-1]: because of [CLS] & [SEP] token\n",
        "            flag = True\n",
        "            start = index\n",
        "            end = start + len(text_tknz) - 3  # Problem in here\n",
        "            start_end_index_dict[i] = [start, end]\n",
        "\n",
        "            references.append(reference_dict)\n",
        "            qc_list.append(concatenated)\n",
        "\n",
        "            assert tokenizer.decode(concatenated['input_ids'][index:index+(len(text_tknz)-2)]) == tokenizer.decode(text_tknz[1:-1]), 'Decoded strings are not matched.'\n",
        "            break\n",
        "\n",
        "        if (flag == False) & (index == len(concatenated['input_ids'])-1):\n",
        "            # Example: \n",
        "            # tokenizer.decode([3325, 1114, 22311, 5912, 1105, 6284, 18608]), tokenizer.decode([3325, 1114, 22311, 5912, 1105, 6284, 1200])\n",
        "            # ('split with Luckett and Roberson', 'split with Luckett and Rober')\n",
        "            strange_case_cnt += 1\n",
        "            index_to_exclude.append(i)\n",
        "            \n",
        "  print(f\"Strange cases count: {strange_case_cnt}개\")\n",
        "\n",
        "  # start_end_index_dict: need tokenzied-version index \n",
        "  # references: will be used later at metric evaluation \n",
        "  # ihdex_to_exclude: observation indices that will be used to excluded based on error of data itself. \n",
        "  # qc_list: tokenized question+context\n",
        "  return start_end_index_dict, references, index_to_exclude, qc_list\n",
        "\n",
        "start_time = time()\n",
        "preprocessed_for_train = start_end_index(dataset, 'train')\n",
        "preprocessed_for_valid = start_end_index(dataset, 'validation')\n",
        "end_time = time()\n",
        "\n",
        "print(f'elapsed time: {(end_time-start_time)/60}min')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Strange cases count: 1255개\n",
            "Strange cases count: 205개\n",
            "elapsed time: 1.2230188608169557min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quwYUhp49bkp"
      },
      "source": [
        "train_start_end = [preprocessed_for_train[0][k] for k, v in preprocessed_for_train[0].items() if k not in preprocessed_for_train[2]]\n",
        "valid_start_end = [preprocessed_for_valid[0][k] for k, v in preprocessed_for_valid[0].items() if k not in preprocessed_for_valid[2]]\n",
        "\n",
        "train_references = preprocessed_for_train[1]\n",
        "valid_references = preprocessed_for_valid[1]\n",
        "\n",
        "train_concatenated = preprocessed_for_train[3]\n",
        "valid_concatenated = preprocessed_for_valid[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqaaKMKSlhRo"
      },
      "source": [
        "class TCdataset(Dataset):\n",
        "  def __init__(self, concatenated_data: List, label_data):\n",
        "    self.feature = concatenated_data\n",
        "    self.label = label_data\n",
        "    self.data = []\n",
        "    self.concat()\n",
        "\n",
        "  def concat(self):\n",
        "    for i in range(len(self.feature)):\n",
        "      temp = [self.feature[i], self.label[i]]\n",
        "      self.data.append(temp)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.data[index]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TCDatacollator:\n",
        "  tokenizer: PreTrainedTokenizer\n",
        "  max_length: int\n",
        "\n",
        "  def _pad(self, encoded_input, max_length):\n",
        "    current_input = encoded_input['input_ids']\n",
        "    pad_needed = len(current_input) < max_length\n",
        "    cut_needed = len(current_input) >= max_length\n",
        "\n",
        "    if pad_needed:\n",
        "        pad_length = max_length - len(current_input)\n",
        "        encoded_input['input_ids'] = current_input + [self.tokenizer.pad_token_type_id] * pad_length\n",
        "        encoded_input['attention_mask'] = encoded_input['attention_mask'] + [0] * pad_length\n",
        "        encoded_input['token_type_ids'] = encoded_input['token_type_ids'] + [self.tokenizer.pad_token_type_id] * pad_length\n",
        "\n",
        "    elif cut_needed:\n",
        "        encoded_input['input_ids'] = current_input[0:max_length]\n",
        "        encoded_input['attention_mask'] = encoded_input['attention_mask'][0:max_length]\n",
        "        encoded_input['token_type_ids'] = encoded_input['token_type_ids'][0:max_length]\n",
        "\n",
        "    return encoded_input\n",
        "\n",
        "  def masking_attention(self, encoded_input):\n",
        "    token_type_ids = encoded_input['token_type_ids']\n",
        "    end_idx = token_type_ids.index(1)\n",
        "    for i in range(end_idx):\n",
        "      encoded_input['attention_mask'][i] = 0\n",
        "\n",
        "    return encoded_input\n",
        "\n",
        "  def __call__(self, tokenized: List[List]):\n",
        "    feature_data = []\n",
        "    label_data = []\n",
        "\n",
        "    for instance in tokenized:\n",
        "      label_data.append(instance[1])\n",
        "      feature_data.append(self.masking_attention(instance[0]))\n",
        "\n",
        "    feature_batch = {}\n",
        "    for encoded_input in feature_data:\n",
        "      outputs_padded = self._pad(encoded_input, self.max_length)\n",
        "      for key, values in outputs_padded.items():\n",
        "        if key not in feature_batch:\n",
        "          feature_batch[key] = []\n",
        "        feature_batch[key].append(values)\n",
        "    feature_batch = {\n",
        "        key: torch.tensor(feature_batch[key]) for key in feature_batch.keys()\n",
        "    }\n",
        "    \n",
        "    feature_batch = BatchEncoding(feature_batch)\n",
        "    label_data = torch.LongTensor(label_data)\n",
        "\n",
        "    return feature_batch, label_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya5BmmGHLmCM"
      },
      "source": [
        "# class TCModel(nn.Module):\n",
        "#   def __init__(self, model_args, config):\n",
        "#     super(TCModel, self).__init__()\n",
        "#     self.config = config\n",
        "#     self.BertModel = Bert(model_args, config=self.config)\n",
        "#     #self.start_proj = nn.Linear(self.config.hidden_size, 1)\n",
        "#     #self.end_proj = nn.Linear(self.config.hidden_size, 1)\n",
        "\n",
        "#   def forward(self, x):\n",
        "#     output = self.BertModel(x)\n",
        "#     #start_output = self.start_proj(output)\n",
        "#     #end_output = self.end_proj(output)\n",
        "    \n",
        "#     return start_output, end_output\n",
        "\n",
        "# class Bert(PreTrainedModel):\n",
        "#     def __init__(self, model_args, config):\n",
        "#         super(Bert, self).__init__(config)\n",
        "#         self.model = AutoModelForQuestionAnswering.from_pretrained(model_args, config=config)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         output = self.model(**x)\n",
        "#         hidden = output[2]\n",
        "#         last_hidden = hidden[-1]\n",
        "        \n",
        "#         del output, hidden\n",
        "\n",
        "#         return last_hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "5e65bccb404f4ee7bf598312b777d182",
            "b19ebe1c3a8440c09eb2ccb35bcb0711",
            "e1d6fbd830b0436fb2754718253d765e"
          ]
        },
        "id": "-PGVxkeIQAVy",
        "scrolled": true,
        "outputId": "81bf70f9-0d7c-4835-e351-4a2eedd2436b"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "config = AutoConfig.from_pretrained('bert-base-cased')\n",
        "                                    #output_hidden_states=True)\n",
        "# model = TCModel('bert-base-cased', config).to(device)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained('bert-base-cased').to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "CELoss = nn.CrossEntropyLoss()\n",
        "\n",
        "train_dataset = TCdataset(train_concatenated, train_start_end)\n",
        "data_collator = TCDatacollator(tokenizer, config.max_position_embeddings)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                                batch_size=16,\n",
        "                                                collate_fn=data_collator,\n",
        "                                                shuffle=True,\n",
        "                                                drop_last=True)\n",
        "\n",
        "train_loss_list = []\n",
        "\n",
        "model.train()\n",
        "for epoch in range(3):\n",
        "  train_loss = 0\n",
        "  for batch_idx, (feature, label) in enumerate(tqdm(train_loader)):\n",
        "    feature = feature.to(device)\n",
        "    label = label.to(device)\n",
        "    \n",
        "    outputs = model(**feature, start_positions = label[:,0].unsqueeze(-1), \n",
        "                          end_positions = label[:,1].unsqueeze(-1))\n",
        "    loss = outputs.loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss\n",
        "\n",
        "    if batch_idx % 50 == 0:\n",
        "      print('Epoch: %03d/%03d | Batch %04d/%04d | Loss: %.4f' \n",
        "      %(epoch+1, 3, batch_idx, len(train_loader), loss))\n",
        "          \n",
        "  train_loss_list.append(train_loss/len(train_loader))\n",
        "\n",
        "#torch.save(model.state_dict(), '/home/swryu/BERT.pt')\n",
        "print(f\"Loss change: {train_loss_list[0]} -> {train_loss_list[1]} -> {train_loss_list[2]}\")\n",
        "\n",
        "del train_loader, train_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e65bccb404f4ee7bf598312b777d182",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5396), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001/003 | Batch 0000/5396 | Loss: 6.1880\n",
            "Epoch: 001/003 | Batch 0050/5396 | Loss: 4.4782\n",
            "Epoch: 001/003 | Batch 0100/5396 | Loss: 3.8132\n",
            "Epoch: 001/003 | Batch 0150/5396 | Loss: 3.7035\n",
            "Epoch: 001/003 | Batch 0200/5396 | Loss: 3.5584\n",
            "Epoch: 001/003 | Batch 0250/5396 | Loss: 3.4089\n",
            "Epoch: 001/003 | Batch 0300/5396 | Loss: 3.5540\n",
            "Epoch: 001/003 | Batch 0350/5396 | Loss: 3.6111\n",
            "Epoch: 001/003 | Batch 0400/5396 | Loss: 3.5176\n",
            "Epoch: 001/003 | Batch 0450/5396 | Loss: 3.0958\n",
            "Epoch: 001/003 | Batch 0500/5396 | Loss: 3.7522\n",
            "Epoch: 001/003 | Batch 0550/5396 | Loss: 3.7506\n",
            "Epoch: 001/003 | Batch 0600/5396 | Loss: 2.9920\n",
            "Epoch: 001/003 | Batch 0650/5396 | Loss: 3.6073\n",
            "Epoch: 001/003 | Batch 0700/5396 | Loss: 3.8295\n",
            "Epoch: 001/003 | Batch 0750/5396 | Loss: 3.1477\n",
            "Epoch: 001/003 | Batch 0800/5396 | Loss: 3.5156\n",
            "Epoch: 001/003 | Batch 0850/5396 | Loss: 2.8582\n",
            "Epoch: 001/003 | Batch 0900/5396 | Loss: 3.6547\n",
            "Epoch: 001/003 | Batch 0950/5396 | Loss: 3.7198\n",
            "Epoch: 001/003 | Batch 1000/5396 | Loss: 3.2936\n",
            "Epoch: 001/003 | Batch 1050/5396 | Loss: 3.6033\n",
            "Epoch: 001/003 | Batch 1100/5396 | Loss: 3.5617\n",
            "Epoch: 001/003 | Batch 1150/5396 | Loss: 3.7620\n",
            "Epoch: 001/003 | Batch 1200/5396 | Loss: 3.4839\n",
            "Epoch: 001/003 | Batch 1250/5396 | Loss: 3.3494\n",
            "Epoch: 001/003 | Batch 1300/5396 | Loss: 3.5038\n",
            "Epoch: 001/003 | Batch 1350/5396 | Loss: 3.2186\n",
            "Epoch: 001/003 | Batch 1400/5396 | Loss: 3.8933\n",
            "Epoch: 001/003 | Batch 1450/5396 | Loss: 3.2618\n",
            "Epoch: 001/003 | Batch 1500/5396 | Loss: 3.5646\n",
            "Epoch: 001/003 | Batch 1550/5396 | Loss: 3.1352\n",
            "Epoch: 001/003 | Batch 1600/5396 | Loss: 3.3995\n",
            "Epoch: 001/003 | Batch 1650/5396 | Loss: 4.0294\n",
            "Epoch: 001/003 | Batch 1700/5396 | Loss: 3.3990\n",
            "Epoch: 001/003 | Batch 1750/5396 | Loss: 3.6361\n",
            "Epoch: 001/003 | Batch 1800/5396 | Loss: 3.5197\n",
            "Epoch: 001/003 | Batch 1850/5396 | Loss: 3.3196\n",
            "Epoch: 001/003 | Batch 1900/5396 | Loss: 3.2426\n",
            "Epoch: 001/003 | Batch 1950/5396 | Loss: 3.0521\n",
            "Epoch: 001/003 | Batch 2000/5396 | Loss: 3.2846\n",
            "Epoch: 001/003 | Batch 2050/5396 | Loss: 3.4208\n",
            "Epoch: 001/003 | Batch 2100/5396 | Loss: 3.0545\n",
            "Epoch: 001/003 | Batch 2150/5396 | Loss: 3.4821\n",
            "Epoch: 001/003 | Batch 2200/5396 | Loss: 3.4436\n",
            "Epoch: 001/003 | Batch 2250/5396 | Loss: 3.0760\n",
            "Epoch: 001/003 | Batch 2300/5396 | Loss: 3.3023\n",
            "Epoch: 001/003 | Batch 2350/5396 | Loss: 3.5553\n",
            "Epoch: 001/003 | Batch 2400/5396 | Loss: 3.3362\n",
            "Epoch: 001/003 | Batch 2450/5396 | Loss: 3.4339\n",
            "Epoch: 001/003 | Batch 2500/5396 | Loss: 2.5853\n",
            "Epoch: 001/003 | Batch 2550/5396 | Loss: 3.3233\n",
            "Epoch: 001/003 | Batch 2600/5396 | Loss: 3.6363\n",
            "Epoch: 001/003 | Batch 2650/5396 | Loss: 3.2156\n",
            "Epoch: 001/003 | Batch 2700/5396 | Loss: 3.6326\n",
            "Epoch: 001/003 | Batch 2750/5396 | Loss: 3.9748\n",
            "Epoch: 001/003 | Batch 2800/5396 | Loss: 3.0305\n",
            "Epoch: 001/003 | Batch 2850/5396 | Loss: 3.6568\n",
            "Epoch: 001/003 | Batch 2900/5396 | Loss: 3.4077\n",
            "Epoch: 001/003 | Batch 2950/5396 | Loss: 3.7028\n",
            "Epoch: 001/003 | Batch 3000/5396 | Loss: 3.1529\n",
            "Epoch: 001/003 | Batch 3050/5396 | Loss: 3.3686\n",
            "Epoch: 001/003 | Batch 3100/5396 | Loss: 3.1145\n",
            "Epoch: 001/003 | Batch 3150/5396 | Loss: 3.5252\n",
            "Epoch: 001/003 | Batch 3200/5396 | Loss: 3.4442\n",
            "Epoch: 001/003 | Batch 3250/5396 | Loss: 3.3736\n",
            "Epoch: 001/003 | Batch 3300/5396 | Loss: 3.6079\n",
            "Epoch: 001/003 | Batch 3350/5396 | Loss: 3.1437\n",
            "Epoch: 001/003 | Batch 3400/5396 | Loss: 3.0695\n",
            "Epoch: 001/003 | Batch 3450/5396 | Loss: 3.0024\n",
            "Epoch: 001/003 | Batch 3500/5396 | Loss: 3.4070\n",
            "Epoch: 001/003 | Batch 3550/5396 | Loss: 3.2387\n",
            "Epoch: 001/003 | Batch 3600/5396 | Loss: 3.4636\n",
            "Epoch: 001/003 | Batch 3650/5396 | Loss: 3.2808\n",
            "Epoch: 001/003 | Batch 3700/5396 | Loss: 3.3529\n",
            "Epoch: 001/003 | Batch 3750/5396 | Loss: 3.8834\n",
            "Epoch: 001/003 | Batch 3800/5396 | Loss: 2.9846\n",
            "Epoch: 001/003 | Batch 3850/5396 | Loss: 3.6451\n",
            "Epoch: 001/003 | Batch 3900/5396 | Loss: 3.3301\n",
            "Epoch: 001/003 | Batch 3950/5396 | Loss: 3.3146\n",
            "Epoch: 001/003 | Batch 4000/5396 | Loss: 3.1962\n",
            "Epoch: 001/003 | Batch 4050/5396 | Loss: 3.2753\n",
            "Epoch: 001/003 | Batch 4100/5396 | Loss: 2.8993\n",
            "Epoch: 001/003 | Batch 4150/5396 | Loss: 3.5172\n",
            "Epoch: 001/003 | Batch 4200/5396 | Loss: 3.2723\n",
            "Epoch: 001/003 | Batch 4250/5396 | Loss: 3.0390\n",
            "Epoch: 001/003 | Batch 4300/5396 | Loss: 2.7567\n",
            "Epoch: 001/003 | Batch 4350/5396 | Loss: 3.2597\n",
            "Epoch: 001/003 | Batch 4400/5396 | Loss: 3.0123\n",
            "Epoch: 001/003 | Batch 4450/5396 | Loss: 2.8445\n",
            "Epoch: 001/003 | Batch 4500/5396 | Loss: 2.9564\n",
            "Epoch: 001/003 | Batch 4550/5396 | Loss: 2.9448\n",
            "Epoch: 001/003 | Batch 4600/5396 | Loss: 3.5120\n",
            "Epoch: 001/003 | Batch 4650/5396 | Loss: 2.8965\n",
            "Epoch: 001/003 | Batch 4700/5396 | Loss: 3.0602\n",
            "Epoch: 001/003 | Batch 4750/5396 | Loss: 3.8765\n",
            "Epoch: 001/003 | Batch 4800/5396 | Loss: 3.2302\n",
            "Epoch: 001/003 | Batch 4850/5396 | Loss: 3.1152\n",
            "Epoch: 001/003 | Batch 4900/5396 | Loss: 3.1434\n",
            "Epoch: 001/003 | Batch 4950/5396 | Loss: 3.4985\n",
            "Epoch: 001/003 | Batch 5000/5396 | Loss: 3.2561\n",
            "Epoch: 001/003 | Batch 5050/5396 | Loss: 3.3817\n",
            "Epoch: 001/003 | Batch 5100/5396 | Loss: 3.2327\n",
            "Epoch: 001/003 | Batch 5150/5396 | Loss: 3.3837\n",
            "Epoch: 001/003 | Batch 5200/5396 | Loss: 3.7220\n",
            "Epoch: 001/003 | Batch 5250/5396 | Loss: 3.3747\n",
            "Epoch: 001/003 | Batch 5300/5396 | Loss: 3.2455\n",
            "Epoch: 001/003 | Batch 5350/5396 | Loss: 3.0473\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b19ebe1c3a8440c09eb2ccb35bcb0711",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5396), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 002/003 | Batch 0000/5396 | Loss: 3.4899\n",
            "Epoch: 002/003 | Batch 0050/5396 | Loss: 2.9654\n",
            "Epoch: 002/003 | Batch 0100/5396 | Loss: 3.1698\n",
            "Epoch: 002/003 | Batch 0150/5396 | Loss: 3.2676\n",
            "Epoch: 002/003 | Batch 0200/5396 | Loss: 3.2993\n",
            "Epoch: 002/003 | Batch 0250/5396 | Loss: 3.4782\n",
            "Epoch: 002/003 | Batch 0300/5396 | Loss: 3.9385\n",
            "Epoch: 002/003 | Batch 0350/5396 | Loss: 3.2470\n",
            "Epoch: 002/003 | Batch 0400/5396 | Loss: 3.4119\n",
            "Epoch: 002/003 | Batch 0450/5396 | Loss: 3.4544\n",
            "Epoch: 002/003 | Batch 0500/5396 | Loss: 3.0175\n",
            "Epoch: 002/003 | Batch 0550/5396 | Loss: 3.2446\n",
            "Epoch: 002/003 | Batch 0600/5396 | Loss: 3.2799\n",
            "Epoch: 002/003 | Batch 0650/5396 | Loss: 3.7610\n",
            "Epoch: 002/003 | Batch 0700/5396 | Loss: 2.8513\n",
            "Epoch: 002/003 | Batch 0750/5396 | Loss: 3.5548\n",
            "Epoch: 002/003 | Batch 0800/5396 | Loss: 3.6414\n",
            "Epoch: 002/003 | Batch 0850/5396 | Loss: 3.2959\n",
            "Epoch: 002/003 | Batch 0900/5396 | Loss: 3.5500\n",
            "Epoch: 002/003 | Batch 0950/5396 | Loss: 3.2973\n",
            "Epoch: 002/003 | Batch 1000/5396 | Loss: 3.5523\n",
            "Epoch: 002/003 | Batch 1050/5396 | Loss: 2.8875\n",
            "Epoch: 002/003 | Batch 1100/5396 | Loss: 3.6097\n",
            "Epoch: 002/003 | Batch 1150/5396 | Loss: 3.3669\n",
            "Epoch: 002/003 | Batch 1200/5396 | Loss: 3.3407\n",
            "Epoch: 002/003 | Batch 1250/5396 | Loss: 3.1160\n",
            "Epoch: 002/003 | Batch 1300/5396 | Loss: 2.8679\n",
            "Epoch: 002/003 | Batch 1350/5396 | Loss: 3.2807\n",
            "Epoch: 002/003 | Batch 1400/5396 | Loss: 2.9294\n",
            "Epoch: 002/003 | Batch 1450/5396 | Loss: 3.1934\n",
            "Epoch: 002/003 | Batch 1500/5396 | Loss: 2.9243\n",
            "Epoch: 002/003 | Batch 1550/5396 | Loss: 2.9216\n",
            "Epoch: 002/003 | Batch 1600/5396 | Loss: 3.3701\n",
            "Epoch: 002/003 | Batch 1650/5396 | Loss: 2.9100\n",
            "Epoch: 002/003 | Batch 1700/5396 | Loss: 3.4492\n",
            "Epoch: 002/003 | Batch 1750/5396 | Loss: 3.3412\n",
            "Epoch: 002/003 | Batch 1800/5396 | Loss: 2.8956\n",
            "Epoch: 002/003 | Batch 1850/5396 | Loss: 2.9358\n",
            "Epoch: 002/003 | Batch 1900/5396 | Loss: 2.8933\n",
            "Epoch: 002/003 | Batch 1950/5396 | Loss: 3.0105\n",
            "Epoch: 002/003 | Batch 2000/5396 | Loss: 3.0151\n",
            "Epoch: 002/003 | Batch 2050/5396 | Loss: 3.1506\n",
            "Epoch: 002/003 | Batch 2100/5396 | Loss: 3.4330\n",
            "Epoch: 002/003 | Batch 2150/5396 | Loss: 3.5360\n",
            "Epoch: 002/003 | Batch 2200/5396 | Loss: 3.6226\n",
            "Epoch: 002/003 | Batch 2250/5396 | Loss: 3.3391\n",
            "Epoch: 002/003 | Batch 2300/5396 | Loss: 2.8495\n",
            "Epoch: 002/003 | Batch 2350/5396 | Loss: 2.9803\n",
            "Epoch: 002/003 | Batch 2400/5396 | Loss: 2.7452\n",
            "Epoch: 002/003 | Batch 2450/5396 | Loss: 2.9986\n",
            "Epoch: 002/003 | Batch 2500/5396 | Loss: 3.1648\n",
            "Epoch: 002/003 | Batch 2550/5396 | Loss: 3.2667\n",
            "Epoch: 002/003 | Batch 2600/5396 | Loss: 3.3412\n",
            "Epoch: 002/003 | Batch 2650/5396 | Loss: 2.6581\n",
            "Epoch: 002/003 | Batch 2700/5396 | Loss: 3.2105\n",
            "Epoch: 002/003 | Batch 2750/5396 | Loss: 3.1838\n",
            "Epoch: 002/003 | Batch 2800/5396 | Loss: 3.4112\n",
            "Epoch: 002/003 | Batch 2850/5396 | Loss: 2.8654\n",
            "Epoch: 002/003 | Batch 2900/5396 | Loss: 3.3414\n",
            "Epoch: 002/003 | Batch 2950/5396 | Loss: 3.3124\n",
            "Epoch: 002/003 | Batch 3000/5396 | Loss: 3.6385\n",
            "Epoch: 002/003 | Batch 3050/5396 | Loss: 3.0396\n",
            "Epoch: 002/003 | Batch 3100/5396 | Loss: 2.7784\n",
            "Epoch: 002/003 | Batch 3150/5396 | Loss: 3.3395\n",
            "Epoch: 002/003 | Batch 3200/5396 | Loss: 3.3375\n",
            "Epoch: 002/003 | Batch 3250/5396 | Loss: 3.3160\n",
            "Epoch: 002/003 | Batch 3300/5396 | Loss: 3.2940\n",
            "Epoch: 002/003 | Batch 3350/5396 | Loss: 3.5346\n",
            "Epoch: 002/003 | Batch 3400/5396 | Loss: 3.1935\n",
            "Epoch: 002/003 | Batch 3450/5396 | Loss: 3.4730\n",
            "Epoch: 002/003 | Batch 3500/5396 | Loss: 2.5881\n",
            "Epoch: 002/003 | Batch 3550/5396 | Loss: 3.4066\n",
            "Epoch: 002/003 | Batch 3600/5396 | Loss: 3.0948\n",
            "Epoch: 002/003 | Batch 3650/5396 | Loss: 3.4157\n",
            "Epoch: 002/003 | Batch 3700/5396 | Loss: 3.0482\n",
            "Epoch: 002/003 | Batch 3750/5396 | Loss: 2.7030\n",
            "Epoch: 002/003 | Batch 3800/5396 | Loss: 2.7822\n",
            "Epoch: 002/003 | Batch 3850/5396 | Loss: 3.0994\n",
            "Epoch: 002/003 | Batch 3900/5396 | Loss: 3.2735\n",
            "Epoch: 002/003 | Batch 3950/5396 | Loss: 3.1988\n",
            "Epoch: 002/003 | Batch 4000/5396 | Loss: 3.4274\n",
            "Epoch: 002/003 | Batch 4050/5396 | Loss: 3.1227\n",
            "Epoch: 002/003 | Batch 4100/5396 | Loss: 3.6199\n",
            "Epoch: 002/003 | Batch 4150/5396 | Loss: 3.2138\n",
            "Epoch: 002/003 | Batch 4200/5396 | Loss: 2.8613\n",
            "Epoch: 002/003 | Batch 4250/5396 | Loss: 2.7863\n",
            "Epoch: 002/003 | Batch 4300/5396 | Loss: 3.0450\n",
            "Epoch: 002/003 | Batch 4350/5396 | Loss: 3.2775\n",
            "Epoch: 002/003 | Batch 4400/5396 | Loss: 3.5306\n",
            "Epoch: 002/003 | Batch 4450/5396 | Loss: 3.2376\n",
            "Epoch: 002/003 | Batch 4500/5396 | Loss: 3.0092\n",
            "Epoch: 002/003 | Batch 4550/5396 | Loss: 3.1152\n",
            "Epoch: 002/003 | Batch 4600/5396 | Loss: 3.4462\n",
            "Epoch: 002/003 | Batch 4650/5396 | Loss: 3.1358\n",
            "Epoch: 002/003 | Batch 4700/5396 | Loss: 2.9218\n",
            "Epoch: 002/003 | Batch 4750/5396 | Loss: 3.3149\n",
            "Epoch: 002/003 | Batch 4800/5396 | Loss: 2.8753\n",
            "Epoch: 002/003 | Batch 4850/5396 | Loss: 3.0863\n",
            "Epoch: 002/003 | Batch 4900/5396 | Loss: 3.2193\n",
            "Epoch: 002/003 | Batch 4950/5396 | Loss: 2.7592\n",
            "Epoch: 002/003 | Batch 5000/5396 | Loss: 3.4213\n",
            "Epoch: 002/003 | Batch 5050/5396 | Loss: 3.0182\n",
            "Epoch: 002/003 | Batch 5100/5396 | Loss: 3.3633\n",
            "Epoch: 002/003 | Batch 5150/5396 | Loss: 3.1500\n",
            "Epoch: 002/003 | Batch 5200/5396 | Loss: 3.1381\n",
            "Epoch: 002/003 | Batch 5250/5396 | Loss: 2.7220\n",
            "Epoch: 002/003 | Batch 5300/5396 | Loss: 3.0717\n",
            "Epoch: 002/003 | Batch 5350/5396 | Loss: 3.2531\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1d6fbd830b0436fb2754718253d765e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5396), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 003/003 | Batch 0000/5396 | Loss: 2.9613\n",
            "Epoch: 003/003 | Batch 0050/5396 | Loss: 3.0108\n",
            "Epoch: 003/003 | Batch 0100/5396 | Loss: 2.9963\n",
            "Epoch: 003/003 | Batch 0150/5396 | Loss: 3.3332\n",
            "Epoch: 003/003 | Batch 0200/5396 | Loss: 3.0031\n",
            "Epoch: 003/003 | Batch 0250/5396 | Loss: 3.0275\n",
            "Epoch: 003/003 | Batch 0300/5396 | Loss: 2.8364\n",
            "Epoch: 003/003 | Batch 0350/5396 | Loss: 2.6646\n",
            "Epoch: 003/003 | Batch 0400/5396 | Loss: 2.8803\n",
            "Epoch: 003/003 | Batch 0450/5396 | Loss: 3.2381\n",
            "Epoch: 003/003 | Batch 0500/5396 | Loss: 3.1962\n",
            "Epoch: 003/003 | Batch 0550/5396 | Loss: 3.2599\n",
            "Epoch: 003/003 | Batch 0600/5396 | Loss: 3.2583\n",
            "Epoch: 003/003 | Batch 0650/5396 | Loss: 3.1052\n",
            "Epoch: 003/003 | Batch 0700/5396 | Loss: 2.5415\n",
            "Epoch: 003/003 | Batch 0750/5396 | Loss: 2.9614\n",
            "Epoch: 003/003 | Batch 0800/5396 | Loss: 3.1267\n",
            "Epoch: 003/003 | Batch 0850/5396 | Loss: 3.1132\n",
            "Epoch: 003/003 | Batch 0900/5396 | Loss: 3.1599\n",
            "Epoch: 003/003 | Batch 0950/5396 | Loss: 2.8251\n",
            "Epoch: 003/003 | Batch 1000/5396 | Loss: 3.3136\n",
            "Epoch: 003/003 | Batch 1050/5396 | Loss: 3.0726\n",
            "Epoch: 003/003 | Batch 1100/5396 | Loss: 2.7803\n",
            "Epoch: 003/003 | Batch 1150/5396 | Loss: 2.7521\n",
            "Epoch: 003/003 | Batch 1200/5396 | Loss: 2.6062\n",
            "Epoch: 003/003 | Batch 1250/5396 | Loss: 3.1596\n",
            "Epoch: 003/003 | Batch 1300/5396 | Loss: 3.2442\n",
            "Epoch: 003/003 | Batch 1350/5396 | Loss: 2.9732\n",
            "Epoch: 003/003 | Batch 1400/5396 | Loss: 2.7451\n",
            "Epoch: 003/003 | Batch 1450/5396 | Loss: 2.7096\n",
            "Epoch: 003/003 | Batch 1500/5396 | Loss: 2.9812\n",
            "Epoch: 003/003 | Batch 1550/5396 | Loss: 2.9208\n",
            "Epoch: 003/003 | Batch 1600/5396 | Loss: 3.0914\n",
            "Epoch: 003/003 | Batch 1650/5396 | Loss: 3.0716\n",
            "Epoch: 003/003 | Batch 1700/5396 | Loss: 3.4757\n",
            "Epoch: 003/003 | Batch 1750/5396 | Loss: 2.6702\n",
            "Epoch: 003/003 | Batch 1800/5396 | Loss: 2.5100\n",
            "Epoch: 003/003 | Batch 1850/5396 | Loss: 3.1690\n",
            "Epoch: 003/003 | Batch 1900/5396 | Loss: 3.2460\n",
            "Epoch: 003/003 | Batch 1950/5396 | Loss: 3.1501\n",
            "Epoch: 003/003 | Batch 2000/5396 | Loss: 3.2926\n",
            "Epoch: 003/003 | Batch 2050/5396 | Loss: 3.3603\n",
            "Epoch: 003/003 | Batch 2100/5396 | Loss: 2.8362\n",
            "Epoch: 003/003 | Batch 2150/5396 | Loss: 2.9295\n",
            "Epoch: 003/003 | Batch 2200/5396 | Loss: 3.1724\n",
            "Epoch: 003/003 | Batch 2250/5396 | Loss: 3.1661\n",
            "Epoch: 003/003 | Batch 2300/5396 | Loss: 3.0352\n",
            "Epoch: 003/003 | Batch 2350/5396 | Loss: 2.5399\n",
            "Epoch: 003/003 | Batch 2400/5396 | Loss: 2.8941\n",
            "Epoch: 003/003 | Batch 2450/5396 | Loss: 2.8775\n",
            "Epoch: 003/003 | Batch 2500/5396 | Loss: 3.1720\n",
            "Epoch: 003/003 | Batch 2550/5396 | Loss: 3.1775\n",
            "Epoch: 003/003 | Batch 2600/5396 | Loss: 2.8529\n",
            "Epoch: 003/003 | Batch 2650/5396 | Loss: 2.7792\n",
            "Epoch: 003/003 | Batch 2700/5396 | Loss: 3.0043\n",
            "Epoch: 003/003 | Batch 2750/5396 | Loss: 2.7830\n",
            "Epoch: 003/003 | Batch 2800/5396 | Loss: 3.1194\n",
            "Epoch: 003/003 | Batch 2850/5396 | Loss: 3.0278\n",
            "Epoch: 003/003 | Batch 2900/5396 | Loss: 3.0535\n",
            "Epoch: 003/003 | Batch 2950/5396 | Loss: 2.5087\n",
            "Epoch: 003/003 | Batch 3000/5396 | Loss: 2.9200\n",
            "Epoch: 003/003 | Batch 3050/5396 | Loss: 2.9921\n",
            "Epoch: 003/003 | Batch 3100/5396 | Loss: 3.1281\n",
            "Epoch: 003/003 | Batch 3150/5396 | Loss: 2.9917\n",
            "Epoch: 003/003 | Batch 3200/5396 | Loss: 2.9929\n",
            "Epoch: 003/003 | Batch 3250/5396 | Loss: 3.1492\n",
            "Epoch: 003/003 | Batch 3300/5396 | Loss: 3.0627\n",
            "Epoch: 003/003 | Batch 3350/5396 | Loss: 3.1488\n",
            "Epoch: 003/003 | Batch 3400/5396 | Loss: 3.2227\n",
            "Epoch: 003/003 | Batch 3450/5396 | Loss: 3.2943\n",
            "Epoch: 003/003 | Batch 3500/5396 | Loss: 2.8318\n",
            "Epoch: 003/003 | Batch 3550/5396 | Loss: 3.4988\n",
            "Epoch: 003/003 | Batch 3600/5396 | Loss: 3.2502\n",
            "Epoch: 003/003 | Batch 3650/5396 | Loss: 2.7210\n",
            "Epoch: 003/003 | Batch 3700/5396 | Loss: 2.8549\n",
            "Epoch: 003/003 | Batch 3750/5396 | Loss: 3.0950\n",
            "Epoch: 003/003 | Batch 3800/5396 | Loss: 2.8173\n",
            "Epoch: 003/003 | Batch 3850/5396 | Loss: 3.2422\n",
            "Epoch: 003/003 | Batch 3900/5396 | Loss: 2.9527\n",
            "Epoch: 003/003 | Batch 3950/5396 | Loss: 3.4727\n",
            "Epoch: 003/003 | Batch 4000/5396 | Loss: 2.7674\n",
            "Epoch: 003/003 | Batch 4050/5396 | Loss: 2.5105\n",
            "Epoch: 003/003 | Batch 4100/5396 | Loss: 3.5514\n",
            "Epoch: 003/003 | Batch 4150/5396 | Loss: 2.7171\n",
            "Epoch: 003/003 | Batch 4200/5396 | Loss: 3.2688\n",
            "Epoch: 003/003 | Batch 4250/5396 | Loss: 3.1548\n",
            "Epoch: 003/003 | Batch 4300/5396 | Loss: 3.1791\n",
            "Epoch: 003/003 | Batch 4350/5396 | Loss: 3.5447\n",
            "Epoch: 003/003 | Batch 4400/5396 | Loss: 2.7617\n",
            "Epoch: 003/003 | Batch 4450/5396 | Loss: 3.2723\n",
            "Epoch: 003/003 | Batch 4500/5396 | Loss: 3.1623\n",
            "Epoch: 003/003 | Batch 4550/5396 | Loss: 3.2513\n",
            "Epoch: 003/003 | Batch 4600/5396 | Loss: 2.8794\n",
            "Epoch: 003/003 | Batch 4650/5396 | Loss: 3.4681\n",
            "Epoch: 003/003 | Batch 4700/5396 | Loss: 3.0551\n",
            "Epoch: 003/003 | Batch 4750/5396 | Loss: 3.2876\n",
            "Epoch: 003/003 | Batch 4800/5396 | Loss: 2.9991\n",
            "Epoch: 003/003 | Batch 4850/5396 | Loss: 2.8808\n",
            "Epoch: 003/003 | Batch 4900/5396 | Loss: 3.1498\n",
            "Epoch: 003/003 | Batch 4950/5396 | Loss: 2.7788\n",
            "Epoch: 003/003 | Batch 5000/5396 | Loss: 3.0826\n",
            "Epoch: 003/003 | Batch 5050/5396 | Loss: 2.9722\n",
            "Epoch: 003/003 | Batch 5100/5396 | Loss: 2.9379\n",
            "Epoch: 003/003 | Batch 5150/5396 | Loss: 3.1382\n",
            "Epoch: 003/003 | Batch 5200/5396 | Loss: 3.1708\n",
            "Epoch: 003/003 | Batch 5250/5396 | Loss: 3.1253\n",
            "Epoch: 003/003 | Batch 5300/5396 | Loss: 2.9486\n",
            "Epoch: 003/003 | Batch 5350/5396 | Loss: 3.3150\n",
            "\n",
            "Loss change: 3.4046716690063477 -> 3.187307596206665 -> 3.021763801574707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "f0543381585a461db3f1acc0b8100626"
          ]
        },
        "id": "h_JvJuR0j0om",
        "outputId": "91dfd277-041b-41ef-cede-dac58fb41490"
      },
      "source": [
        "predictions = []\n",
        "valid_dataset = TCdataset(valid_concatenated, valid_start_end)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
        "                                           batch_size=1,\n",
        "                                           collate_fn=data_collator,\n",
        "                                           shuffle = False,\n",
        "                                           drop_last=True)\n",
        "model.eval()\n",
        "for batch_idx, (feature, _) in enumerate(tqdm(valid_loader)):\n",
        "    pred_dict = dict()\n",
        "    feature_input_ids = feature['input_ids'][0]\n",
        "    \n",
        "    with torch.no_grad(): \n",
        "        feature = feature.to(device)\n",
        "        \n",
        "        outputs = model(**feature)\n",
        "        start_logit = outputs.start_logits\n",
        "        end_logit = outputs.end_logits\n",
        "                \n",
        "        start_idx = torch.argmax(start_logit, dim=1)[0].item()\n",
        "        end_idx = torch.argmax(end_logit, dim=1)[0].item()\n",
        "        \n",
        "        if start_idx <= end_idx:\n",
        "            words = tokenizer.decode(feature_input_ids[start_idx:end_idx+1])\n",
        "            pred_dict['prediction_text'] = words\n",
        "        else:\n",
        "            pred_dict['prediction_text'] = 'wrong' # Just to fill in the metric format \n",
        "        \n",
        "        pred_dict['id'] = valid_references[batch_idx]['id']\n",
        "        predictions.append(pred_dict)\n",
        "           \n",
        "results = squad_metric.compute(predictions=predictions, references=valid_references)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0543381585a461db3f1acc0b8100626",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=10365), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "{'exact_match': 7.361312108055958, 'f1': 10.79437052268124}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuWpEWr6TTs1"
      },
      "source": [
        "**Problem 3.2** *(10 points)* How does your question answering accuracy (F1 and EM) with BERT compares to your accuracy with LSTM and Attention in Assignment 2? How about training speed?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8jaOh99j0on"
      },
      "source": [
        "**Answer to Problem 3.2** EM and F1 scores in BERT outperformed those of LSTM+Attention. Especially, in F1 score, I recorded less than 1 in case of LSTM+Attentions. However, in this case, I recorded about 10 times higher in BERT's case. However, because BERT model uses transformers in their encoder, it takes much more computation time comparing to LSTM. It took about one and an half hour for finetuning with 3 epochs!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HOkVUPtTU1y"
      },
      "source": [
        "\n",
        "**Problem 3.3** *(10 points)* Try your own context/questions and find three failure cases. Explain why you think the model got them wrong."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD57Zo9Oj0on"
      },
      "source": [
        "**Answer to Problem 3.3** The three cases I made failed to predict the result exactly. This failure happened due to the limitation of the sequence length: 256. When the question and context is concatenated, if the text is located at the out of bound (All the three cases below corresponds to this case), model cannot expect the result however it learns the parameters well! This is the limitation of the model itself, not caused by model's underperforming."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxw9aGk9j0on"
      },
      "source": [
        "question1 = 'Which class was the best class you took in a first semester of KAIST graduate life?'\n",
        "context_base = 'I thankfully got a permission from KAIST, and I started to study in here from March, 2021. ' +\\\n",
        "'I took three classes in this semester. Natural Language Processing, Deep Learning, and Machine Learning for Health Care! ' +\\\n",
        "'I learned a lot of things in those  classes. In Natural Language Processing class, I leart a lot of general topics such as NER, QA, etc. ' +\\\n",
        "'And of course I learnt a lot of models such as RNN, LSTM, Seq2seq models, transformers and transformer variants, and large language models!. ' +\\\n",
        "'In Deep Learning courses, for the first half of the class, I learnt about Deep Learning basics. On the second half, ' +\\\n",
        "'I learnt about some image tasks and natural language processing tasks. ' +\\\n",
        "'For the last, in case of Machine Learning for Health Care class,I learnt a lot of backgrounds about medical tasks: ' +\\\n",
        "'MIMIC3 data, and a lot of visual, language, graphical models. '+\\\n",
        "'All those three classes were very nice. I satisfy at all those three classes. '+\\\n",
        "'Those three classes were really helpful for me though I took about 10 coding assignments. '+\\\n",
        "'Semester is not ended yet, and still have so much things to do. '\n",
        "\n",
        "context1 = context_base + 'And of course the best class was the class taught by professor Min Joon Seo.'\n",
        "context2 = context_base + 'I took three classes, and my answer is NLP.'\n",
        "context3 = context_base + 'Natural Language Processing'\n",
        "\n",
        "text1 = 'the class taught by professor Min Joon Seo'\n",
        "text2 = 'NLP'\n",
        "text3 = 'Natural Language Processing'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3Cm8mLkj0on"
      },
      "source": [
        "def find_index(context, text, max_length=256):\n",
        "    qc_tknz = tokenizer(context, text, max_length=max_length, return_tensors='pt').to(device)\n",
        "    text_tknz = tokenizer(text, return_tensors='pt').to(device)\n",
        "    qc_input_ids = qc_tknz['input_ids'][0]\n",
        "    qc_input_len = len(qc_input_ids)\n",
        "    \n",
        "    start = None\n",
        "    end = None\n",
        "    for i in range(qc_input_len):\n",
        "        if torch.equal(qc_input_ids[i:(i+len(text_tknz['input_ids'][0])-2)], text_tknz['input_ids'][0][1:-1]):\n",
        "            start = i\n",
        "            end = i + qc_input_len-1\n",
        "            continue\n",
        "            \n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    with torch.no_grad():\n",
        "        logit1, logit2 = model(qc_tknz)\n",
        "        start_idx = torch.argmax(logit1, dim=1)[0].item()\n",
        "        end_idx = torch.argmax(logit2, dim=1)[0].item()\n",
        "        output = tokenizer.decode(qc_input_ids[start_idx:end_idx+1])\n",
        "        \n",
        "        print(f'The real answer        : {text}')\n",
        "        print(f'What the model expected: {output}')\n",
        "        print('-----------------------------------')\n",
        "        \n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkDlhiizj0on",
        "outputId": "e8f0ebd2-f5dc-490d-e84e-6b8f4c11c09d"
      },
      "source": [
        "find_index(context1, text1)\n",
        "find_index(context2, text2)\n",
        "find_index(context3, text3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The real answer        : the class taught by professor Min Joon Seo\n",
            "What the model expected: Natural Language Processing, Deep Learning, and Machine Learning for Health Care\n",
            "-----------------------------------\n",
            "The real answer        : NLP\n",
            "What the model expected: Natural Language Processing, Deep Learning, and Machine Learning for Health Care\n",
            "-----------------------------------\n",
            "The real answer        : Natural Language Processing\n",
            "What the model expected: Natural Language Processing, Deep Learning, and Machine Learning for Health Care\n",
            "-----------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br5m8jjaKll_"
      },
      "source": [
        "**Problem 3.4 (bonus)** *(20 points)* Can we do better than truncating tokens if the input length is too long? Suggest (but do not code) a strategy for a problem like SQuAD when the input has an arbitrary length with a pretrained model like BERT that has a predefined input length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YmObLiLj0oo"
      },
      "source": [
        "**Answer to Problem 3.4** I think I can improve the performance by using the sliding window techniques. For example, in case of bert-base with sequence length 512, I have to cut or pad real inputs to fit the input sequence length into 512. However, general Bert just considers 512 sequences at the very front and cut. It means we lose precious information at the rear side. Rather than just cut, if we cannot avoid truncation, we can cut by length 512 from front to the back. And then take average of the outputs at the last layer. It might also contain might-be precious information."
      ]
    }
  ]
}