## AI605 Natural Language Processing  

* I thankfully got a permission to upload baseline codes from professor `Minjoon, Seo`.     
* Base codes written on Google `Colab`  
---  

### Assignment1: Text Classification with RNNs  
- Task: Make Baseline, RNN, and LSTM models (with variants) from scratch using Pytorch  
  ```  
  * Self-Reflection *
  1. Should have used 'DataLoader' to load minibatch faster (Bottleneck happened due to the absence of DataLoader)
  2. Should have made meticulous first-draft for scalability before start coding  
  3. Necessity to be familiar with Hugging Face  
  ```  

### Assignment2: Token Classification with RNNs and Attention  
- Task: Do a token classification task following some guidelines.  
  ```  
  * Self-Reflection * 
  At #4 LSTM+Attention for SQuAD part, loss was exponentially decreased comparing to previous tasks.  
  It happened after forwarding attention mechanism. I debugged but couldn't find the reason. Spent too much time at debugging.  
  ```  
  
### Assignment3: Paper writing assignment  
- No codes attached.  
